- apiVersion: openslo/v1
  kind: SLO
  metadata:
    displayName: AI Agent Response Time
    labels:
      audience:
      - sre
      category:
      - latency
      domain:
      - ai-ml
      framework:
      - red
      layer:
      - service
      metric-type:
      - duration
      scope:
      - customer-facing
      severity:
      - high
      tier:
      - p0
    name: agent-response-time
  spec:
    budgetingMethod: Occurrences
    description: Ensure AI agents respond quickly to user queries for good user experience
    indicator:
      metadata:
        displayName: P95 response time for agent queries
        name: agent-p95-latency
      spec:
        thresholdMetric:
          metricSource:
            spec:
              query: histogram_quantile(0.95, rate(agent_response_duration_seconds_bucket[5m]))
            type: Prometheus
    objectives:
    - displayName: Fast response time
      op: lt
      target: 0.95
      value: 3
    service: ai-agent-platform
    timeWindow:
    - duration: 1w
      isRolling: true
- apiVersion: openslo/v1
  kind: SLO
  metadata:
    displayName: Per-User Response Time
    labels:
      audience:
      - sre
      category:
      - latency
      domain:
      - ai-ml
      framework:
      - red
      layer:
      - service
      metric-type:
      - duration
      scope:
      - customer-facing
      severity:
      - high
      tier:
      - p0
    name: per-user-response-time
  spec:
    budgetingMethod: Timeslices
    description: Monitor response time per user to ensure consistent performance
    indicator:
      metadata:
        displayName: Percentage of users with acceptable response times
        name: user-response-time
      spec:
        ratioMetric:
          counter: false
          good:
            metricSource:
              spec:
                query: count(histogram_quantile(0.95, sum by(user_id, le) (rate(agent_response_duration_seconds_bucket[1h])))
                  < 3)
              type: Prometheus
          total:
            metricSource:
              spec:
                query: count(sum by(user_id) (rate(agent_response_duration_seconds_count[1h])))
              type: Prometheus
    objectives:
    - displayName: Consistent performance
      target: 0.95
      timeSliceTarget: 0.9
      timeSliceWindow: 1h
    service: ai-agent-platform
    timeWindow:
    - duration: 1w
      isRolling: true
- apiVersion: openslo/v1
  kind: SLO
  metadata:
    displayName: AI Agent First Token Latency
    labels:
      audience:
      - sre
      category:
      - latency
      domain:
      - ai-ml
      framework:
      - red
      layer:
      - service
      metric-type:
      - duration
      scope:
      - customer-facing
      severity:
      - high
      tier:
      - p1
    name: agent-first-token-latency
  spec:
    budgetingMethod: Occurrences
    description: Track time to first token in streaming responses for perceived responsiveness
    indicator:
      metadata:
        displayName: P95 time to first token
        name: first-token-latency
      spec:
        thresholdMetric:
          metricSource:
            spec:
              query: histogram_quantile(0.95, rate(agent_first_token_duration_seconds_bucket[5m]))
            type: Prometheus
    objectives:
    - displayName: Responsive streaming
      op: lt
      target: 0.95
      value: 0.5
    service: ai-agent-platform
    timeWindow:
    - duration: 1w
      isRolling: true
